{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ab226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e71cc30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define base path to the dataset\n",
    "BASE_DATA_PATH = Path(\"../exercise_01/aclImdb\")\n",
    "\n",
    "TRAIN_PATH = BASE_DATA_PATH / \"train\"\n",
    "TEST_PATH = BASE_DATA_PATH / \"test\"\n",
    "\n",
    "TRAIN_POS_PATH = TRAIN_PATH / \"pos\"\n",
    "TRAIN_NEG_PATH = TRAIN_PATH / \"neg\"\n",
    "TEST_POS_PATH = TEST_PATH / \"pos\"\n",
    "TEST_NEG_PATH = TEST_PATH / \"neg\"\n",
    "\n",
    "assert (\n",
    "    TRAIN_POS_PATH.exists()\n",
    "    and TRAIN_NEG_PATH.exists()\n",
    "    and TEST_POS_PATH.exists()\n",
    "    and TEST_NEG_PATH.exists()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3d000ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000 training reviews (subset).\n",
      "Training labels distribution: Positive (1): 2511, Negative (0): 2489\n",
      "Loaded 25000 test reviews.\n",
      "Test labels distribution: Positive (1): 12500, Negative (0): 12500\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def load_imdb_data(\n",
    "    data_path: Path, subset_size: int | None = None, random_seed: int = 42\n",
    ") -> tuple[list[str], list[int]]:\n",
    "    \"\"\"\n",
    "    Loads movie reviews and their sentiments from the specified path.\n",
    "    If subset_size is provided, returns a random subset of that size (with fixed seed).\n",
    "    \"\"\"\n",
    "    texts: list[str] = []\n",
    "    labels: list[int] = []\n",
    "\n",
    "    for sentiment, folder_path in [\n",
    "        (\"pos\", data_path / \"pos\"),\n",
    "        (\"neg\", data_path / \"neg\"),\n",
    "    ]:\n",
    "        if not folder_path.exists():\n",
    "            raise FileNotFoundError(f\"Warning: Path {folder_path} does not exist.\")\n",
    "\n",
    "        binary_label = 1 if sentiment == \"pos\" else 0\n",
    "\n",
    "        for file_path in folder_path.glob(\"*.txt\"):\n",
    "            texts.append(file_path.read_text(encoding=\"utf-8\"))\n",
    "            labels.append(binary_label)  # Use binary label, not score\n",
    "\n",
    "    if subset_size is not None and subset_size < len(texts):\n",
    "        random.seed(random_seed)\n",
    "        indices = list(range(len(texts)))\n",
    "        random.shuffle(indices)\n",
    "        selected_indices = indices[:subset_size]\n",
    "        texts = [texts[i] for i in selected_indices]\n",
    "        labels = [labels[i] for i in selected_indices]\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "# Set the subset size for training data (e.g., 5000 for a smaller subset)\n",
    "TRAIN_SUBSET_SIZE = 5000  # Change as needed\n",
    "\n",
    "# Load training data (random subset)\n",
    "train_texts_raw, train_labels = load_imdb_data(\n",
    "    TRAIN_PATH, subset_size=TRAIN_SUBSET_SIZE, random_seed=42\n",
    ")\n",
    "print(f\"Loaded {len(train_texts_raw)} training reviews (subset).\")\n",
    "print(\n",
    "    f\"Training labels distribution: Positive (1): {sum(train_labels)}, Negative (0): {len(train_labels) - sum(train_labels)}\"\n",
    ")\n",
    "\n",
    "# Load test data (full set)\n",
    "test_texts_raw, test_labels = load_imdb_data(TEST_PATH)\n",
    "print(f\"Loaded {len(test_texts_raw)} test reviews.\")\n",
    "print(\n",
    "    f\"Test labels distribution: Positive (1): {sum(test_labels)}, Negative (0): {len(test_labels) - sum(test_labels)}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2e2dcf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['This is one of those movies that you and a bunch of friends sit around drinking beers, eating pizza, and laugh at. Unfortunately for me I found myself watching this one alone. My friends and I rented a big block of movies and never got around to seeing this one. It was due back and I figured that it was a waste not to watch it. So I did, and I was impressed at how absolutely terrible this movie is.<br /><br />Now, I love bad movies quite a bit, and I probably would have liked this one if the \"hero\" wasn\\'t so utterly loathsome. The entire movie I was hoping that he\\'d put that stupid sword down and let someone kill him! He does very little heroic things in the movie. He\\'s a beefy, disgusting, stupid thing. He has less redeeming qualities than the villains do. And what was it with all the naked chicks? I mean, I love naked chicks just as much as the next guy, but this movie went a tad overboard in that department.<br /><br />Well, anyway, if you love bad movies and can stand a disgusting \"hero\" then I\\'m sure you\\'ll like this schlock of a film.',\n",
       "  'This documentary on schlockmeister William Castle takes a few cheap shots at the naive \\'50s-\\'60s environment in which he did his most characteristic work--look at the funny, silly people with the ghost-glasses--but it\\'s also affectionate and lively, with particularly bright commentary from John Waters, who was absolutely the target audience for such things at the time, and from Castle\\'s daughter, who adored her dad and also is pretty perceptive about how he plied his craft. (We never find out what became of the other Castle offspring.) The movies were not very good, it makes clear, but his marketing of them was brilliant, and he appears to have been a sweet, hardworking family man. Fun people keep popping up, like \"Straight Jacket\"\\'s Diane Baker, who looks great, and Anne Helm, whom she replaced at the instigation of star Joan Crawford. Darryl Hickman all but explodes into giggles at the happy memory of working with Castle on \"The Tingler,\" and there\\'s enough footage to give us an idea of the level of Castle\\'s talent--not very high, but very energetic. A pleasant look at a time when audiences were more easily pleased, and it does make you nostalgic for simpler movie-going days.'],\n",
       " [0, 1])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts_raw[:2], train_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "17b4a680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing default behavior...\n",
      "Testing lowercase=False...\n",
      "Testing replace_numbers=False...\n",
      "Testing tokenize_punct=True, remove_punct=False...\n",
      "Testing tokenize_punct=True, remove_punct=True...\n",
      "Testing tokenize_punct=False, remove_punct=False...\n",
      "Testing high-frequency removal (threshold=0.7)...\n",
      "Testing high-frequency removal (threshold=0.6)...\n",
      "Testing edge cases...\n",
      "\n",
      "✅ All tests for the pre_process function passed successfully!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from typing import List, Set\n",
    "\n",
    "\n",
    "def pre_process(\n",
    "    reviews: List[str],\n",
    "    tokenize_punct: bool = False,\n",
    "    lowercase: bool = True,\n",
    "    remove_punct: bool = True,\n",
    "    remove_high_freq_terms: bool = False,\n",
    "    high_freq_threshold: float = 0.5,\n",
    "    replace_numbers: bool = True,\n",
    ") -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Pre-processes a list of text reviews by tokenizing, cleaning, and normalizing them.\n",
    "\n",
    "    Args:\n",
    "        reviews (List[str]): A list of raw review strings.\n",
    "        tokenize_punct (bool): If True, punctuation marks are treated as separate tokens.\n",
    "                               If False, punctuation is discarded during tokenization.\n",
    "        lowercase (bool): If True, converts all text to lowercase.\n",
    "        remove_punct (bool): If True, removes punctuation tokens.\n",
    "                             Note: This is only effective if `tokenize_punct` is True.\n",
    "        remove_high_freq_terms (bool): If True, removes words that appear in more than\n",
    "                                       `high_freq_threshold` proportion of documents.\n",
    "        high_freq_threshold (float): The document frequency threshold for removing terms.\n",
    "        replace_numbers (bool): If True, replaces all sequences of digits with a 'num' token.\n",
    "\n",
    "    Returns:\n",
    "        List[List[str]]: A list of processed reviews, where each review is a list of tokens.\n",
    "    \"\"\"\n",
    "    processed_reviews: List[List[str]] = []\n",
    "    punct_set: Set[str] = set(string.punctuation)\n",
    "\n",
    "    for review in reviews:\n",
    "        text: str = review\n",
    "        if lowercase:\n",
    "            text = text.lower()\n",
    "        if replace_numbers:\n",
    "            # Use a simple token 'num' that is compatible with the tokenizer.\n",
    "            text = re.sub(r\"\\d+\", \"num\", text)\n",
    "\n",
    "        # Tokenize based on the specified flag\n",
    "        if tokenize_punct:\n",
    "            # Keeps words and punctuation as separate tokens\n",
    "            tokens: List[str] = re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "        else:\n",
    "            # Keeps only word characters, effectively discarding punctuation\n",
    "            tokens: List[str] = re.findall(r\"\\w+\", text)\n",
    "\n",
    "        # This step is only effective if tokenize_punct=True\n",
    "        if remove_punct and tokenize_punct:\n",
    "            tokens = [token for token in tokens if token not in punct_set]\n",
    "\n",
    "        processed_reviews.append(tokens)\n",
    "\n",
    "    if remove_high_freq_terms:\n",
    "        doc_freq = Counter()\n",
    "        # Calculate document frequency (word appears in how many docs)\n",
    "        for tokens_list in processed_reviews:\n",
    "            doc_freq.update(set(tokens_list))\n",
    "\n",
    "        num_docs: int = len(processed_reviews)\n",
    "        # Identify terms that are too frequent\n",
    "        high_freq_terms = {\n",
    "            term\n",
    "            for term, freq in doc_freq.items()\n",
    "            if (freq / num_docs) > high_freq_threshold\n",
    "        }\n",
    "\n",
    "        # Filter out the high-frequency terms from all reviews\n",
    "        processed_reviews = [\n",
    "            [token for token in tokens_list if token not in high_freq_terms]\n",
    "            for tokens_list in processed_reviews\n",
    "        ]\n",
    "\n",
    "    return processed_reviews\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# ==================== FINAL CORRECTED TEST SUITE ==============================\n",
    "# ==============================================================================\n",
    "\n",
    "# Define a controlled test corpus to check all behaviors\n",
    "test_corpus = [\n",
    "    \"Hello common world! This is test 123.\",\n",
    "    \"Another common sentence, with a unique word.\",\n",
    "    \"Just a common sentence.\",\n",
    "]\n",
    "\n",
    "# --- Test 1: Default behavior ---\n",
    "print(\"Testing default behavior...\")\n",
    "processed = pre_process(test_corpus)\n",
    "expected_default = [\n",
    "    [\"hello\", \"common\", \"world\", \"this\", \"is\", \"test\", \"num\"],\n",
    "    [\"another\", \"common\", \"sentence\", \"with\", \"a\", \"unique\", \"word\"],\n",
    "    [\"just\", \"a\", \"common\", \"sentence\"],\n",
    "]\n",
    "assert processed == expected_default, f\"Default test failed. Got: {processed}\"\n",
    "\n",
    "# --- Test 2: `lowercase=False` ---\n",
    "print(\"Testing lowercase=False...\")\n",
    "processed = pre_process(test_corpus, lowercase=False)\n",
    "expected_no_lower = [\n",
    "    [\"Hello\", \"common\", \"world\", \"This\", \"is\", \"test\", \"num\"],\n",
    "    [\"Another\", \"common\", \"sentence\", \"with\", \"a\", \"unique\", \"word\"],\n",
    "    [\"Just\", \"a\", \"common\", \"sentence\"],\n",
    "]\n",
    "assert processed == expected_no_lower, f\"lowercase=False test failed. Got: {processed}\"\n",
    "\n",
    "# --- Test 3: `replace_numbers=False` ---\n",
    "print(\"Testing replace_numbers=False...\")\n",
    "processed = pre_process(test_corpus, replace_numbers=False)\n",
    "expected_no_num_replace = [\n",
    "    [\"hello\", \"common\", \"world\", \"this\", \"is\", \"test\", \"123\"],\n",
    "    [\"another\", \"common\", \"sentence\", \"with\", \"a\", \"unique\", \"word\"],\n",
    "    [\"just\", \"a\", \"common\", \"sentence\"],\n",
    "]\n",
    "assert processed == expected_no_num_replace, (\n",
    "    f\"replace_numbers=False test failed. Got: {processed}\"\n",
    ")\n",
    "\n",
    "# --- Test 4: Punctuation Handling ---\n",
    "print(\"Testing tokenize_punct=True, remove_punct=False...\")\n",
    "processed = pre_process(test_corpus, tokenize_punct=True, remove_punct=False)\n",
    "expected_keep_punct = [\n",
    "    [\"hello\", \"common\", \"world\", \"!\", \"this\", \"is\", \"test\", \"num\", \".\"],\n",
    "    [\"another\", \"common\", \"sentence\", \",\", \"with\", \"a\", \"unique\", \"word\", \".\"],\n",
    "    [\"just\", \"a\", \"common\", \"sentence\", \".\"],\n",
    "]\n",
    "assert processed == expected_keep_punct, (\n",
    "    f\"Keep punctuation test failed. Got: {processed}\"\n",
    ")\n",
    "\n",
    "print(\"Testing tokenize_punct=True, remove_punct=True...\")\n",
    "processed = pre_process(test_corpus, tokenize_punct=True, remove_punct=True)\n",
    "assert processed == expected_default, (\n",
    "    f\"Tokenize then remove punctuation test failed. Got: {processed}\"\n",
    ")\n",
    "\n",
    "print(\"Testing tokenize_punct=False, remove_punct=False...\")\n",
    "processed = pre_process(test_corpus, tokenize_punct=False, remove_punct=False)\n",
    "assert processed == expected_default, (\n",
    "    f\"Discard punctuation test failed. Got: {processed}\"\n",
    ")\n",
    "\n",
    "# --- Test 5: High-Frequency Term Removal ---\n",
    "print(\"Testing high-frequency removal (threshold=0.7)...\")\n",
    "processed = pre_process(\n",
    "    test_corpus, remove_high_freq_terms=True, high_freq_threshold=0.7\n",
    ")\n",
    "expected_remove_common = [\n",
    "    [\"hello\", \"world\", \"this\", \"is\", \"test\", \"num\"],\n",
    "    [\"another\", \"sentence\", \"with\", \"a\", \"unique\", \"word\"],\n",
    "    [\"just\", \"a\", \"sentence\"],\n",
    "]\n",
    "assert processed == expected_remove_common, (\n",
    "    f\"High-freq removal (0.7) test failed. Got: {processed}\"\n",
    ")\n",
    "\n",
    "print(\"Testing high-frequency removal (threshold=0.6)...\")\n",
    "processed = pre_process(\n",
    "    test_corpus, remove_high_freq_terms=True, high_freq_threshold=0.6\n",
    ")\n",
    "# CORRECTED: The word 'a' should also be removed as its doc freq (0.667) > 0.6\n",
    "expected_remove_common_and_sentence = [\n",
    "    [\"hello\", \"world\", \"this\", \"is\", \"test\", \"num\"],\n",
    "    [\"another\", \"with\", \"unique\", \"word\"],\n",
    "    [\"just\"],\n",
    "]\n",
    "assert processed == expected_remove_common_and_sentence, (\n",
    "    f\"High-freq removal (0.6) test failed. Got: {processed}\"\n",
    ")\n",
    "\n",
    "# --- Test 6: Edge Cases ---\n",
    "print(\"Testing edge cases...\")\n",
    "assert pre_process([]) == [], \"Edge case: Empty list failed.\"\n",
    "assert pre_process([\"\"]) == [[]], \"Edge case: List with empty string failed.\"\n",
    "assert pre_process([\"!@#$\"]) == [[]], (\n",
    "    \"Edge case: Punctuation-only string (default) failed.\"\n",
    ")\n",
    "assert pre_process([\"!@#$\"], tokenize_punct=True, remove_punct=False) == [\n",
    "    [\"!\", \"@\", \"#\", \"$\"]\n",
    "], \"Edge case: Punctuation-only string (keep) failed.\"\n",
    "\n",
    "print(\"\\n✅ All tests for the pre_process function passed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "eb1195c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = pre_process(train_texts_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9d301948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'documentary',\n",
       " 'on',\n",
       " 'schlockmeister',\n",
       " 'william',\n",
       " 'castle',\n",
       " 'takes',\n",
       " 'a',\n",
       " 'few',\n",
       " 'cheap',\n",
       " '...',\n",
       " 'it',\n",
       " 'does',\n",
       " 'make',\n",
       " 'you',\n",
       " 'nostalgic',\n",
       " 'for',\n",
       " 'simpler',\n",
       " 'movie',\n",
       " 'going',\n",
       " 'days']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus[1][:10] + [\"...\"] + tokenized_corpus[1][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "90e96e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hanged', 'etebari', 'ladder', 'sexists', 'buzzkill', '...', 'despot', 'p', 'fairview', '<PAD>', '<UNK>']\n",
      "Vocab Size 38281\n",
      "PAD token index: 38279\n",
      "UNK token index: 38280\n"
     ]
    }
   ],
   "source": [
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "# Vocabulary\n",
    "vocab = list(set(word for sentence in tokenized_corpus for word in sentence))\n",
    "\n",
    "# Add special tokens\n",
    "if PAD_TOKEN not in vocab:\n",
    "    vocab.append(PAD_TOKEN)\n",
    "if UNK_TOKEN not in vocab:\n",
    "    vocab.append(UNK_TOKEN)\n",
    "\n",
    "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(vocab[:5] + [\"...\"] + vocab[-5:])\n",
    "\n",
    "print(\"Vocab Size\", vocab_size)\n",
    "print(f\"PAD token index: {word_to_idx[PAD_TOKEN]}\")\n",
    "print(f\"UNK token index: {word_to_idx[UNK_TOKEN]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343e407",
   "metadata": {},
   "source": [
    "### RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d4d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a7a60933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s', 'great', 'student', 'bodies', 'styled', 'gags', 'br', 'br', 'too', 'bad', 'this', 'isn', 't', 'on', 'video', 'but', 'you', 'can', 'still', 'watch', 'it', 'on', 'flix', '<PAD>', '<PAD>']\n",
      "['were', 'the', 'last', 'movie', 'on', 'earth', 'great', 'actors', 'but', 'bad', 'script', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "['it', 's', 'just', 'basically', 'a', 'wonderfull', 'movie', 'for', 'all', 'ages', 'i', 'found', 'the', 'last', 'battle', 'scene', 'awesome', 'basically', 'this', 'was', 'a', 'great', 'flick', '<PAD>', '<PAD>']\n",
      "['s', 'the', 'only', 'porn', 'movie', 'i', 'know', 'that', 'is', 'worth', 'watching', 'between', 'the', 'sex', 'scenes', 'br', 'br', 'bon', 'cinema', 'br', 'br', 'laurent', '<PAD>', '<PAD>', '<PAD>']\n",
      "['still', 'a', 'very', 'good', 'movie', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 50\n",
    "\n",
    "\n",
    "def truncate_or_pad(\n",
    "    sentence: list[str], pad_token=PAD_TOKEN, sequence_length=SEQUENCE_LENGTH\n",
    ") -> list[str]:\n",
    "    if len(sentence) >= sequence_length:\n",
    "        output = sentence[:sequence_length]\n",
    "    else:\n",
    "        output = sentence + [pad_token] * (sequence_length - len(sentence))\n",
    "\n",
    "    assert len(output) == sequence_length\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "training_inputs = [truncate_or_pad(sentence) for sentence in tokenized_corpus]\n",
    "\n",
    "\n",
    "assert all(len(sentence) == SEQUENCE_LENGTH for sentence in training_inputs)\n",
    "\n",
    "for sentence in [s for s in training_inputs if PAD_TOKEN in s][:5]:\n",
    "    print(sentence[25:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b5ccfa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class RNNDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, inputs: list[list[str]], labels: list[int], word_to_idx: dict[str, int]\n",
    "    ):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.unk_idx = word_to_idx[UNK_TOKEN]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        sentence = self.inputs[idx]\n",
    "        # Handle unknown words by mapping them to UNK token\n",
    "        indices = [self.word_to_idx.get(word, self.unk_idx) for word in sentence]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(indices, dtype=torch.long), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19635c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, hidden_dim:int, dropout_prob:float=0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=vocab_size, embedding_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "        self.input_to_hidden= nn.Linear(in_features=embedding_dim, out_features=hidden_dim)\n",
    "        self.hidden_to_hidden = nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "\n",
    "        self.regression = nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "\n",
    "    def forward(self, sentences: torch.Tensor):\n",
    "        batch_size, sequence_length = sentences.shape\n",
    "\n",
    "        previous_memories = torch.zeros((batch_size, self.hidden_dim), device=sentences.device)\n",
    "\n",
    "        for i in range(sequence_length):\n",
    "            tokens = sentences[:, i]\n",
    "\n",
    "            embeddings = self.embeddings(tokens)\n",
    "\n",
    "            new_memories = torch.tanh(self.input_to_hidden(embeddings) + self.hidden_to_hidden(previous_memories))\n",
    "            new_memories = self.dropout(new_memories)\n",
    "            previous_memories = new_memories\n",
    "\n",
    "        return self.regression(new_memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0ac40118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Train Loss: 0.6977 | Train Acc: 0.5120 | Test Loss: 0.6967 | Test Acc: 0.5012\n",
      "Epoch [2/20] | Train Loss: 0.6839 | Train Acc: 0.5556 | Test Loss: 0.7003 | Test Acc: 0.5135\n",
      "Epoch [3/20] | Train Loss: 0.6665 | Train Acc: 0.5978 | Test Loss: 0.7094 | Test Acc: 0.5164\n",
      "Epoch [4/20] | Train Loss: 0.6336 | Train Acc: 0.6380 | Test Loss: 0.7188 | Test Acc: 0.5425\n",
      "Epoch [5/20] | Train Loss: 0.5836 | Train Acc: 0.6922 | Test Loss: 0.7396 | Test Acc: 0.5600\n",
      "Epoch [6/20] | Train Loss: 0.5336 | Train Acc: 0.7246 | Test Loss: 0.7977 | Test Acc: 0.5714\n",
      "Epoch [7/20] | Train Loss: 0.4651 | Train Acc: 0.7746 | Test Loss: 0.8279 | Test Acc: 0.5782\n",
      "Epoch [8/20] | Train Loss: 0.3988 | Train Acc: 0.8126 | Test Loss: 0.8893 | Test Acc: 0.5677\n",
      "Epoch [9/20] | Train Loss: 0.3473 | Train Acc: 0.8402 | Test Loss: 0.9470 | Test Acc: 0.5447\n",
      "Epoch [10/20] | Train Loss: 0.2819 | Train Acc: 0.8730 | Test Loss: 1.0409 | Test Acc: 0.5852\n",
      "Epoch [11/20] | Train Loss: 0.2793 | Train Acc: 0.8946 | Test Loss: 1.0163 | Test Acc: 0.5595\n",
      "Epoch [12/20] | Train Loss: 0.1980 | Train Acc: 0.9252 | Test Loss: 1.1688 | Test Acc: 0.5754\n",
      "Epoch [13/20] | Train Loss: 0.1769 | Train Acc: 0.9342 | Test Loss: 1.2061 | Test Acc: 0.5843\n",
      "Epoch [14/20] | Train Loss: 0.1847 | Train Acc: 0.9210 | Test Loss: 1.3128 | Test Acc: 0.5580\n",
      "Epoch [15/20] | Train Loss: 0.1438 | Train Acc: 0.9350 | Test Loss: 1.4036 | Test Acc: 0.5684\n",
      "Epoch [16/20] | Train Loss: 0.1186 | Train Acc: 0.9450 | Test Loss: 1.5555 | Test Acc: 0.5621\n",
      "Epoch [17/20] | Train Loss: 0.1090 | Train Acc: 0.9494 | Test Loss: 1.5954 | Test Acc: 0.5683\n",
      "Epoch [18/20] | Train Loss: 0.0955 | Train Acc: 0.9498 | Test Loss: 1.7054 | Test Acc: 0.5623\n",
      "Epoch [19/20] | Train Loss: 0.1174 | Train Acc: 0.9424 | Test Loss: 1.5258 | Test Acc: 0.5693\n",
      "Epoch [20/20] | Train Loss: 0.0998 | Train Acc: 0.9530 | Test Loss: 1.7739 | Test Acc: 0.5633\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "BATCH_SIZE: int = 32\n",
    "LEARNING_RATE: float = 0.001\n",
    "\n",
    "SEQUENCE_LENGTH: int = 100\n",
    "training_inputs = [truncate_or_pad(sentence, sequence_length=SEQUENCE_LENGTH) for sentence in tokenized_corpus]\n",
    "\n",
    "# Create training dataset (with UNK token handling)\n",
    "train_dataset = RNNDataset(training_inputs, train_labels, word_to_idx=word_to_idx)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM= 50\n",
    "\n",
    "\n",
    "model = RNN(vocab_size=vocab_size, embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM)\n",
    "model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS: int = 20\n",
    "\n",
    "# Lists to store metrics for plotting later\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- Training Phase ---\n",
    "    model.train() # Set the model to training mode\n",
    "    total_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for batch_inputs, batch_labels in train_loader:\n",
    "        batch_inputs, batch_labels = batch_inputs.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        \n",
    "        # Calculate training accuracy for the batch\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).int().squeeze()\n",
    "        correct_train += (preds == batch_labels).sum().item()\n",
    "        total_train += batch_labels.size(0)\n",
    "        \n",
    "        # Calculate loss and update weights\n",
    "        batch_labels = batch_labels.float().unsqueeze(1)\n",
    "        loss = loss_function(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Calculate average training metrics for the epoch\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    epoch_train_acc = correct_train / total_train\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(epoch_train_acc)\n",
    "\n",
    "    # --- Evaluation Phase ---\n",
    "    model.eval() # Set the model to evaluation mode (IMPORTANT!)\n",
    "    total_test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    # Pre-process and load test data once\n",
    "    test_tokenized = pre_process(test_texts_raw)\n",
    "    test_inputs = [truncate_or_pad(s, sequence_length=SEQUENCE_LENGTH) for s in test_tokenized]\n",
    "    test_dataset = RNNDataset(test_inputs, test_labels, word_to_idx=word_to_idx)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    with torch.no_grad(): # Disable gradient calculations (Saves memory and computation)\n",
    "        for batch_inputs, batch_labels in test_loader:\n",
    "            batch_inputs, batch_labels = batch_inputs.to(device), batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_inputs)\n",
    "            \n",
    "            # Calculate test accuracy for the batch\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int().squeeze()\n",
    "            correct_test += (preds == batch_labels).sum().item()\n",
    "            total_test += batch_labels.size(0)\n",
    "            \n",
    "            # Calculate loss\n",
    "            batch_labels = batch_labels.float().unsqueeze(1)\n",
    "            loss = loss_function(outputs, batch_labels)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "    # Calculate average test metrics for the epoch\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    epoch_test_acc = correct_test / total_test\n",
    "    \n",
    "    test_losses.append(avg_test_loss)\n",
    "    test_accuracies.append(epoch_test_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {epoch_train_acc:.4f} | \"\n",
    "          f\"Test Loss: {avg_test_loss:.4f} | Test Acc: {epoch_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b377ee9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 25000\n",
      "Test batches: 782\n",
      "Out-of-vocabulary words in test data: 41964\n",
      "Total unique words in test data: 72915\n",
      "OOV percentage: 57.55%\n"
     ]
    }
   ],
   "source": [
    "# Preprocess test data using the same pipeline as training\n",
    "test_tokenized_corpus = pre_process(test_texts_raw)\n",
    "test_inputs = [truncate_or_pad(sentence) for sentence in test_tokenized_corpus]\n",
    "\n",
    "# Create test dataset (RNNDataset automatically handles OOV words with UNK token)\n",
    "test_dataset = RNNDataset(test_inputs, test_labels, word_to_idx=word_to_idx)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Check how many OOV words we have in test data\n",
    "all_test_words = set(word for sentence in test_tokenized_corpus for word in sentence)\n",
    "train_vocab_words = set(word_to_idx.keys()) - {PAD_TOKEN, UNK_TOKEN}\n",
    "oov_words = all_test_words - train_vocab_words\n",
    "print(f\"Out-of-vocabulary words in test data: {len(oov_words)}\")\n",
    "print(f\"Total unique words in test data: {len(all_test_words)}\")\n",
    "print(f\"OOV percentage: {len(oov_words) / len(all_test_words) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "58eb2821",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[171]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch_inputs, batch_labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m         \u001b[38;5;66;03m# Apply sigmoid to get probabilities\u001b[39;00m\n\u001b[32m     16\u001b[39m         predictions = torch.sigmoid(outputs).squeeze()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/passau/dlnlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/passau/dlnlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[168]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mRNN.forward\u001b[39m\u001b[34m(self, sentences)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sequence_length):\n\u001b[32m     27\u001b[39m     tokens = sentences[:, i]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     new_memories = torch.tanh(\u001b[38;5;28mself\u001b[39m.input_to_hidden(embeddings) + \u001b[38;5;28mself\u001b[39m.hidden_to_hidden(previous_memories))\n\u001b[32m     32\u001b[39m     previous_memories = new_memories\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/passau/dlnlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/passau/dlnlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/passau/dlnlp/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/passau/dlnlp/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Evaluate the model on test data\n",
    "model.eval()\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_inputs, batch_labels in test_loader:\n",
    "        outputs = model(batch_inputs)\n",
    "        \n",
    "        # Apply sigmoid to get probabilities\n",
    "        predictions = torch.sigmoid(outputs).squeeze()\n",
    "        \n",
    "        # Convert to binary predictions (0 or 1)\n",
    "        binary_predictions = (predictions > 0.5).int()\n",
    "        \n",
    "        # Store predictions and labels for analysis\n",
    "        all_predictions.extend(binary_predictions.tolist())\n",
    "        all_labels.extend(batch_labels.tolist())\n",
    "        \n",
    "        # Count correct predictions\n",
    "        correct_predictions += (binary_predictions == batch_labels).sum().item()\n",
    "        total_predictions += batch_labels.size(0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Test Accuracy: {accuracy:.4f} ({correct_predictions}/{total_predictions})\")\n",
    "\n",
    "# Additional metrics\n",
    "prediction_counts = Counter(all_predictions)\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "print(f\"Prediction distribution: {prediction_counts}\")\n",
    "print(f\"True label distribution: {label_counts}\")\n",
    "\n",
    "# Calculate precision, recall, and F1-score for positive class\n",
    "true_positives = sum(1 for pred, true in zip(all_predictions, all_labels) if pred == 1 and true == 1)\n",
    "false_positives = sum(1 for pred, true in zip(all_predictions, all_labels) if pred == 1 and true == 0)\n",
    "false_negatives = sum(1 for pred, true in zip(all_predictions, all_labels) if pred == 0 and true == 1)\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ff2000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example predictions:\n",
      "--------------------------------------------------------------------------------\n",
      "1. ✗ Predicted: Positive | True: Negative\n",
      "   Text: I would like to comment on how the girls are chosen. why is that their are always more white women chosen then their are black women. every episode their is always more white women then black one's. a...\n",
      "\n",
      "2. ✗ Predicted: Negative | True: Positive\n",
      "   Text: What a pleasure. This is really a parody. Only french people can do that kind of thing without being coarse. And as a result, you spend a really good time watching Jean Dujardin playing the dumb. Most...\n",
      "\n",
      "3. ✓ Predicted: Positive | True: Positive\n",
      "   Text: Not having seen the film in its commercial debut, we just caught with it via DVD. Expecting the worst, \"Hitch\" proved to be a pleasant experience because of the three principals in it. Thanks to Andy ...\n",
      "\n",
      "4. ✓ Predicted: Positive | True: Positive\n",
      "   Text: The '70s were a great time for horror movies. The Brotherhood of Satan is yet another overlooked gem. It's full to the brim with great surreal, unsettling scenes. It's also great to see Stother Martin...\n",
      "\n",
      "5. ✓ Predicted: Negative | True: Negative\n",
      "   Text: I am a huge fan of the Farcry Game, HUGE fan. It still holds a place in my top-10 games list of all time! The story line was new, fresh... A truly brilliant foundation to base a movie on... or so i th...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show some example predictions\n",
    "import random\n",
    "\n",
    "def show_predictions(num_examples=5):\n",
    "    indices = random.sample(range(len(all_predictions)), num_examples)\n",
    "    \n",
    "    print(\"Example predictions:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        prediction = all_predictions[idx]\n",
    "        true_label = all_labels[idx]\n",
    "        \n",
    "        # Get the original text (first 200 characters)\n",
    "        original_text = test_texts_raw[idx][:200] + \"...\" if len(test_texts_raw[idx]) > 200 else test_texts_raw[idx]\n",
    "        \n",
    "        status = \"✓\" if prediction == true_label else \"✗\"\n",
    "        sentiment_pred = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "        sentiment_true = \"Positive\" if true_label == 1 else \"Negative\"\n",
    "        \n",
    "        print(f\"{i+1}. {status} Predicted: {sentiment_pred} | True: {sentiment_true}\")\n",
    "        print(f\"   Text: {original_text}\")\n",
    "        print()\n",
    "\n",
    "show_predictions()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
