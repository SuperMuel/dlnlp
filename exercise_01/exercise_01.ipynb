{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd8ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa59a5ec-4e46-4277-a58e-70ba131703a8",
   "metadata": {},
   "source": [
    "# Deep Learning for Natural Language and Code: Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d974f0-1885-437d-b0fb-adf7d95484b6",
   "metadata": {},
   "source": [
    "# Task 1: LIBSVM - BOW\n",
    "\n",
    "## Load data\n",
    "\n",
    "1. Download the dataset from [here](https://ai.stanford.edu/%7Eamaas/data/sentiment)\n",
    "1. Copy the dataset next to this Jupyter (.ipynb file)\n",
    "1. Install:\n",
    "    * Sklearn (This library is only allowed to use for reading the BOW in LIBSVM format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8981d6",
   "metadata": {},
   "source": [
    "A **LIBSVM file** is a plain text file format used to store **sparse datasets** for machine learning tasks, especially **classification** and **regression**. It's called \"LIBSVM\" because it was originally used by the **LIBSVM** library, a very popular library for Support Vector Machines.\n",
    "\n",
    "The format looks like this:\n",
    "\n",
    "```\n",
    "<label> <index1>:<value1> <index2>:<value2> <index3>:<value3> ...\n",
    "```\n",
    "\n",
    "- `<label>` = the **target value** (for example, `1` for positive, `-1` for negative).\n",
    "- `<index>:<value>` = the **non-zero features**.\n",
    "  - `<index>` is the feature number (starting at 1),\n",
    "  - `<value>` is the value of that feature (usually the count or some preprocessed weight).\n",
    "\n",
    "If a feature is **zero**, it is simply **omitted** from the line (to save space — this is why it's called *sparse* format).\n",
    "\n",
    "---\n",
    "\n",
    "### A real small example:\n",
    "\n",
    "Suppose we have two movie reviews turned into a Bag-of-Words (BoW):\n",
    "- Feature 1 = \"awesome\"\n",
    "- Feature 2 = \"terrible\"\n",
    "- Feature 3 = \"boring\"\n",
    "- Feature 4 = \"amazing\"\n",
    "\n",
    "And two reviews:\n",
    "- Review 1 (positive): \"awesome amazing\"\n",
    "- Review 2 (negative): \"terrible boring boring\"\n",
    "\n",
    "The LIBSVM file would look like:\n",
    "\n",
    "```\n",
    "1 1:1 4:1\n",
    "-1 2:1 3:2\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- The first line:\n",
    "  - `1` → label is positive\n",
    "  - `1:1` → \"awesome\" appeared once\n",
    "  - `4:1` → \"amazing\" appeared once\n",
    "- The second line:\n",
    "  - `-1` → label is negative\n",
    "  - `2:1` → \"terrible\" appeared once\n",
    "  - `3:2` → \"boring\" appeared twice\n",
    "\n",
    "---\n",
    "\n",
    "### Why use LIBSVM format?\n",
    "\n",
    "- It's super lightweight for huge datasets where most feature values are 0.\n",
    "- It's easy to parse and generate manually.\n",
    "- Many machine learning tools accept this format directly (e.g., SVM, Random Forest, logistic regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288552ef",
   "metadata": {},
   "source": [
    "**What's inside `./aclImdb/train/labeledBow.feat` ?**\n",
    "\n",
    "- There are 25 000 lines\n",
    "- One line per sample\n",
    "- first element of each line is the label (frol 1 to 10)\n",
    "- others are the number of apparences of each feature (e.g `0:9 1:1` means feature 0 appeared 9 times and the feature 1 appeared only once)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304afa0f",
   "metadata": {},
   "source": [
    "### Warning on dense matrix sizes\n",
    "\n",
    "My custom code initially constructs a dense matrix to represent the libsvm file. \n",
    "- [ ] Compute the size needed in memory to store the dense matrix \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f44a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "type Feature = int\n",
    "type Occurrence = int\n",
    "type Label = int\n",
    "\n",
    "\n",
    "def parse_libsvm_line(line: str) -> tuple[list[tuple[Feature, Occurrence]], Label]:\n",
    "    label, features = line.split(\" \", 1)\n",
    "    features = features.split(\" \")\n",
    "    features = cast(\n",
    "        list[tuple[int, int]],\n",
    "        [tuple(map(int, feature.split(\":\"))) for feature in features],\n",
    "    )\n",
    "    return features, int(label)\n",
    "\n",
    "\n",
    "assert parse_libsvm_line(\"1 0:9 1:1 14:87\") == ([(0, 9), (1, 1), (14, 87)], 1)\n",
    "\n",
    "\n",
    "def parse_libsvm_content(content: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    data = [parse_libsvm_line(line) for line in content.split(\"\\n\") if line]\n",
    "\n",
    "    vocabulary_size = (\n",
    "        max((feature for features, _ in data for feature, _ in features), default=0) + 1\n",
    "    )\n",
    "    X = np.zeros((len(data), vocabulary_size))\n",
    "    y = np.zeros(len(data))\n",
    "    for i, (line, label) in enumerate(data):\n",
    "        for feature, occurrence in line:\n",
    "            X[i, feature] = occurrence\n",
    "        y[i] = label\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = parse_libsvm_content(\"1 0:9 1:1 3:87\\n-1 2:1 3:2\")\n",
    "assert np.all(X == [[9, 1, 0, 87], [0, 0, 1, 2]])\n",
    "assert np.all(y == [1, -1])\n",
    "\n",
    "\n",
    "def load_libsvm_file(path: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    with open(path, \"r\") as f:\n",
    "        return parse_libsvm_content(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6422fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_libsvm_file(\"./aclImdb/train/labeledBow.feat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a02a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efb3393-4a19-40bf-9e5c-557bd1331da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "\n",
    "# X_sklearn, y_sklearn = load_svmlight_file('./aclImdb/train/labeledBow.feat')\n",
    "# Commented out because it's slow\n",
    "\n",
    "# assert X_sklearn.shape == X.shape\n",
    "# assert np.allclose(X_sklearn.todense(), X)\n",
    "# assert np.allclose(y_sklearn, y)\n",
    "# # ->  Good, my implementation is consistent with the sklearn implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b556ad",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1fe5f-277e-4bf4-9498-8225fe7e9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "VOCAB_FILE = Path(\"./aclImdb/imdb.vocab\")\n",
    "assert VOCAB_FILE.exists()\n",
    "\n",
    "\n",
    "def read_vocab(file: Path) -> list[str]:\n",
    "    return file.read_text().splitlines()\n",
    "\n",
    "\n",
    "vocab = read_vocab(VOCAB_FILE)\n",
    "\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d859674d-6750-4159-a5d0-10238bcce7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the the bag of words and the Y for the training data\n",
    "X, y = load_libsvm_file(\"./aclImdb/train/labeledBow.feat\")\n",
    "# Read the the bag of words and the Y for the test data\n",
    "X_test, y_test = load_libsvm_file(\"./aclImdb/test/labeledBow.feat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7180b",
   "metadata": {},
   "source": [
    "### Expected Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f2d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [float(line) for line in open(\"./aclImdb/imdbEr.txt\")]\n",
    "ratings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, rating in list(zip(vocab, ratings))[:10]:\n",
    "    print(f\"{token}: {rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d077a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most negative and most positive words\n",
    "most_negative_words = sorted(zip(ratings, vocab), key=lambda x: x[0])[:10]\n",
    "most_positive_words = sorted(zip(ratings, vocab), key=lambda x: x[0])[-10:]\n",
    "\n",
    "print(\"Most negative words:\")\n",
    "for rating, word in most_negative_words:\n",
    "    print(f\"{word}: {rating}\")\n",
    "\n",
    "print(\"\\nMost positive words:\")\n",
    "for rating, word in most_positive_words:\n",
    "    print(f\"{word}: {rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed720048-0950-4dc1-b78b-29bed1c002ed",
   "metadata": {},
   "source": [
    "# Task 2: Bag of Words (BOW)\n",
    "## Load Raw text and scores \n",
    "\n",
    "1. Be sure to have downloaded the dataset from the link provided in the exercise and have read the README file\n",
    "1. Be sure to have copied the dataset next to this Jupyter (.ipynb file)\n",
    "1. Be sure to have installed:\n",
    "    * Numpy\n",
    "    * NLTK (only for the stemming process)\n",
    "    * Sklearn (only for building a Random Forest)\n",
    "1. In this part of the exercise it is not allowed to use Sklearn\n",
    "1. Build the Bag Of Words (BOW) with the raw data, for this you need to:\n",
    "    * Tokenize on spaces and punctuation\n",
    "    * Lower case\n",
    "    * Remove punctuation\n",
    "    * Remove terms appearing more often than X percent, this X percent should be variable. Which means that you should be able to change the percentage as a parameter.\n",
    "    * Use NLTK porter stemmer\n",
    "1. Build a classifier with the BOW previously built. Take into account:\n",
    "    * The RF should be a binary classification positive (i.e., score >=7) and negative (i.e., score <= 4)\n",
    "    * Test the classifier with the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36bb43",
   "metadata": {},
   "source": [
    "##  Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d5a9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_POS_DIR = Path(\"./aclImdb/train/pos\")\n",
    "TRAIN_NEG_DIR = Path(\"./aclImdb/train/neg\")\n",
    "TEST_POS_DIR = Path(\"./aclImdb/test/pos\")\n",
    "TEST_NEG_DIR = Path(\"./aclImdb/test/neg\")\n",
    "\n",
    "assert (\n",
    "    TRAIN_POS_DIR.exists()\n",
    "    and TRAIN_NEG_DIR.exists()\n",
    "    and TEST_POS_DIR.exists()\n",
    "    and TEST_NEG_DIR.exists()\n",
    ")\n",
    "assert (\n",
    "    TRAIN_POS_DIR.is_dir()\n",
    "    and TRAIN_NEG_DIR.is_dir()\n",
    "    and TEST_POS_DIR.is_dir()\n",
    "    and TEST_NEG_DIR.is_dir()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e154a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts: list[str] = []\n",
    "\n",
    "for dir in TRAIN_POS_DIR, TRAIN_NEG_DIR:\n",
    "    for file in dir.glob(\"*.txt\"):\n",
    "        id, label = map(int, file.name.strip(\".txt\").split(\"_\"))\n",
    "\n",
    "        assert 0 <= id <= 12499\n",
    "        assert 1 <= label <= 10\n",
    "\n",
    "        text = file.read_text()\n",
    "        all_texts.append(text)\n",
    "\n",
    "assert len(all_texts) == 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31fbff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "# I manually set this list of characters to remove\n",
    "# after I detected them in the following cells.\n",
    "# But I could use https://pypi.org/project/Unidecode/ instead\n",
    "CHARACTERS_TO_REMOVE = [\n",
    "    \"\\x96\",\n",
    "    \"\\x91\",\n",
    "    \"\\x97\",\n",
    "    \"\\xad\",\n",
    "    \"\\x84\",\n",
    "    \"\\x08\",\n",
    "    \"\\x80\",\n",
    "    \"\\x8e\",\n",
    "    \"\\x9e\",\n",
    "    \"\\x95\",\n",
    "    \"\\x9a\",\n",
    "    \"\\x10\",\n",
    "    \"\\x8d\",\n",
    "    \"\\uf0b7\",\n",
    "]\n",
    "\n",
    "\n",
    "def clean_text_from_weird_chars(\n",
    "    text: str,\n",
    "    *,\n",
    "    weird_chars: Sequence[str] = CHARACTERS_TO_REMOVE,\n",
    "    replace_with: str = \" \",\n",
    ") -> str:\n",
    "    for char in weird_chars:\n",
    "        text = text.replace(char, replace_with)\n",
    "    return text\n",
    "\n",
    "\n",
    "all_texts = [clean_text_from_weird_chars(text) for text in all_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5392c509",
   "metadata": {},
   "source": [
    "### Analyze lenghts of reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b9845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_text_length_distribution(texts: list[str]) -> None:\n",
    "    lengths = np.array([len(text) for text in texts])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=50, color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.title(\"Distribution of Text Lengths (in characters)\")\n",
    "    plt.xlabel(\"Text Length (characters)\")\n",
    "    plt.ylabel(\"Number of Reviews\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_text_length_distribution(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e3e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_and_longest_reviews(\n",
    "    texts: list[str], n: int = 5\n",
    ") -> tuple[list[str], list[str]]:\n",
    "    \"\"\"\n",
    "    Returns the n shortest and n longest reviews from the given list of texts.\n",
    "\n",
    "    Args:\n",
    "        texts: List of text reviews\n",
    "        n: Number of shortest and longest reviews to return\n",
    "\n",
    "    Returns:\n",
    "        tuple containing lists of shortest and longest reviews\n",
    "    \"\"\"\n",
    "    # Create a list of (text, length) tuples\n",
    "    text_lengths = [(text, len(text)) for text in texts]\n",
    "\n",
    "    # Sort by length\n",
    "    text_lengths.sort(key=lambda x: x[1])\n",
    "\n",
    "    # Get n shortest and n longest\n",
    "    shortest = [text for text, _ in text_lengths[:n]]\n",
    "    longest = [text for text, _ in text_lengths[-n:]]\n",
    "\n",
    "    return shortest, longest\n",
    "\n",
    "\n",
    "# Get 5 shortest and 5 longest reviews\n",
    "shortest_reviews, longest_reviews = get_shortest_and_longest_reviews(all_texts, 5)\n",
    "\n",
    "# Display shortest reviews\n",
    "print(\"5 SHORTEST REVIEWS:\")\n",
    "for i, review in enumerate(shortest_reviews, 1):\n",
    "    print(f\"\\nShortest Review #{i} ({len(review)} characters):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(review[:200] + \"...\" if len(review) > 200 else review)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Display longest reviews\n",
    "print(\"\\n\\n5 LONGEST REVIEWS:\")\n",
    "for i, review in enumerate(longest_reviews, 1):\n",
    "    print(f\"\\nLongest Review #{i} ({len(review)} characters):\")\n",
    "    print(\"-\" * 50)\n",
    "    # Only show the beginning and end of very long reviews\n",
    "    if len(review) > 400:\n",
    "        print(review[:200] + \"\\n...\\n\" + review[-200:])\n",
    "    else:\n",
    "        print(review)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c21cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# def find_non_alphanumeric(texts: list[str]) -> dict[str, int]:\n",
    "#     non_alphanumeric = {}\n",
    "#     for text in texts:\n",
    "#         for char in text:\n",
    "#             if not re.match(r'[A-Za-z0-9\\s]', char):\n",
    "#                 non_alphanumeric[char] = non_alphanumeric.get(char, 0) + 1\n",
    "#     return non_alphanumeric\n",
    "\n",
    "# Find and display non-alphanumeric characters in the reviews\n",
    "def find_non_alphanumeric(texts: list[str]) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Finds all non-alphanumeric characters in the texts and counts their occurrences.\n",
    "\n",
    "    Args:\n",
    "        texts: List of text reviews\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping non-alphanumeric characters to their occurrence counts\n",
    "    \"\"\"\n",
    "    non_alphanumeric = {}\n",
    "\n",
    "    for text in texts:\n",
    "        for char in text:\n",
    "            if char == \"½\":\n",
    "                non_alphanumeric[char] = non_alphanumeric.get(char, 0) + 1\n",
    "            elif not char.isalnum() and not char.isspace():\n",
    "                non_alphanumeric[char] = non_alphanumeric.get(char, 0) + 1\n",
    "\n",
    "    return non_alphanumeric\n",
    "\n",
    "\n",
    "assert find_non_alphanumeric([\"½\"]) == {\"½\": 1}\n",
    "\n",
    "\n",
    "# Get non-alphanumeric characters and their counts\n",
    "non_alphanumeric_chars = find_non_alphanumeric(all_texts)\n",
    "\n",
    "# Sort by frequency (most common first)\n",
    "sorted_chars = sorted(non_alphanumeric_chars.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the results\n",
    "print(\"NON-ALPHANUMERIC CHARACTERS (sorted by frequency):\")\n",
    "print(\"-\" * 50)\n",
    "for char, count in sorted_chars:\n",
    "    print(f\"'{char}': {count} occurrences\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Show some examples of reviews with special characters\n",
    "print(\"\\nEXAMPLES OF REVIEWS WITH SPECIAL CHARACTERS:\")\n",
    "for char, _ in sorted_chars:  # Take top 5 most common special chars\n",
    "    for text in all_texts[:1000]:  # Search in first 1000 reviews for efficiency\n",
    "        if char in text:\n",
    "            print(f\"\\nReview containing '{char}':\")\n",
    "            print(\"-\" * 50)\n",
    "            # Find the position of the character and show context around it\n",
    "            pos = text.find(char)\n",
    "            start = max(0, pos - 50)\n",
    "            end = min(len(text), pos + 50)\n",
    "            context = text[start:end]\n",
    "            # Highlight the character\n",
    "            print(f\"...{context.replace(char, f'[{char}]')}...\")\n",
    "            print(\"-\" * 50)\n",
    "            break  # Only show one example per character\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b6989e",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "\n",
    "\n",
    "Here’s an analysis and categorization of the non-alphanumeric characters you listed, with explanations and examples for each group:\n",
    "\n",
    "---\n",
    "\n",
    "**Punctuation (Standard English)**\n",
    "These are the most common and serve grammatical or stylistic purposes in English text.\n",
    "\n",
    "- **Sentence-ending:**  \n",
    "  - `.` (period), `!` (exclamation), `?` (question mark)\n",
    "- **Pausing/Separating:**  \n",
    "  - `,` (comma), `;` (semicolon), `:` (colon), `-` (hyphen), `–` (en dash), `—` (em dash)\n",
    "- **Quotation/Dialogue:**  \n",
    "  - `'` (apostrophe), `\"` (double quote), `‘’` (curly single quotes), `“”` (curly double quotes)\n",
    "- **Parenthetical/Grouping:**  \n",
    "  - `(`, `)`, `[`, `]`, `{`, `}`\n",
    "- **Other:**  \n",
    "  - `/` (slash), `\\\\` (backslash), `|` (pipe), `*` (asterisk), `&` (ampersand), `#` (hash), `@` (at), `^` (caret), `_` (underscore), `+` (plus), `=` (equals), `%` (percent), `$` (dollar), `~` (tilde), `` ` `` (backtick)\n",
    "\n",
    "\n",
    "\n",
    "**HTML/XML Markup**\n",
    "Characters commonly found in HTML tags or entities, often due to the dataset containing raw web data.\n",
    "\n",
    "- `<`, `>`, `/`  \n",
    "  - Used for opening/closing tags: `<br />`, `<p>`, etc.\n",
    "  - **Also used for the heart symbol \"<3\" : this should not be cleaned away !**\n",
    "\n",
    "**Special/Extended ASCII and Unicode**\n",
    "These include typographic symbols, currency, and accented characters, often from non-English text or encoding artifacts.\n",
    "\n",
    "- **Accented/Foreign Letters:**  \n",
    "  - `´`, `¨`, `¡`, `£`, `¤`, `®`, `°`, ``, `₤`, `¿`\n",
    "- **Typographic/Formatting:**  \n",
    "  - `…` (ellipsis), `·` (middle dot), `§` (section), `¦` (broken bar), `–` (en dash), `—` (em dash), `“”` (curly quotes), `‘’` (curly apostrophes), `«»` (guillemets)\n",
    "\n",
    "**Mathematical/Technical Symbols**\n",
    "Occasionally appear in reviews, especially in ratings or technical discussions.\n",
    "\n",
    "- `*`, `+`, `=`, `%`, `#`, `^`, `|`, `/`, `\\\\`\n",
    "\n",
    "**Currency and Miscellaneous**\n",
    "- `$`, `£`, `₤` (currencies)\n",
    "- `@` (email, social media handles)\n",
    "- `~` (approximation, tilde)\n",
    "- `°` (degree symbol)\n",
    "\n",
    "**Rare/Unusual Characters**\n",
    "- `¿`, `¡` (Spanish punctuation)\n",
    "- `»`, `«` (French/Spanish quotes)\n",
    "- `¤`, `®`, `¦`, `§`, `·`, `¨`, `…` (various typographic or currency symbols)\n",
    "\n",
    "**Whitespace and Control Characters**\n",
    "Not explicitly listed, but often present in text data (e.g., `\\n`, `\\t`, non-breaking space).\n",
    "\n",
    "\n",
    "**NLP Implications**\n",
    "\n",
    "- **Punctuation** is often removed or normalized in preprocessing, but apostrophes and hyphens may be important for meaning (e.g., “don’t”, “re-enter”).\n",
    "- **HTML/XML** should be stripped or converted to plain text.\n",
    "- **Encoding Artifacts** should be cleaned or normalized to avoid noise.\n",
    "- **Special/Unicode** characters may need normalization, especially for multilingual data.\n",
    "- **Currency and Technical Symbols** may be relevant for certain tasks (e.g., financial sentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e42257",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get html tags\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Dictionary to track occurrences of HTML-like tags\n",
    "html_tag_occurrences = defaultdict(int)\n",
    "html_tag_examples = defaultdict(list)\n",
    "\n",
    "# Find all potential HTML tags in the texts\n",
    "for text in all_texts:\n",
    "    # Find all occurrences of patterns that look like HTML tags\n",
    "    potential_tags = re.findall(r\"<[^>]+>\", text)\n",
    "\n",
    "    for tag in potential_tags:\n",
    "        html_tag_occurrences[tag] += 1\n",
    "        # Store up to 3 examples of context for each tag\n",
    "        if len(html_tag_examples[tag]) < 3:\n",
    "            # Get some context around the tag\n",
    "            start_idx = max(0, text.find(tag) - 30)\n",
    "            end_idx = min(len(text), text.find(tag) + len(tag) + 30)\n",
    "            context = text[start_idx:end_idx]\n",
    "            html_tag_examples[tag].append(context)\n",
    "\n",
    "# Display the most common HTML-like tags and their examples\n",
    "print(\"Most common HTML-like tags:\")\n",
    "for tag, count in sorted(\n",
    "    html_tag_occurrences.items(), key=lambda x: x[1], reverse=True\n",
    ")[:500]:\n",
    "    print(f\"{tag}: {count} occurrences\")\n",
    "    print(\"Examples:\")\n",
    "    for example in html_tag_examples[tag]:\n",
    "        print(f\"  - ...{example}...\")\n",
    "    print()\n",
    "\n",
    "# Also check for individual < and > characters that might not be part of tags\n",
    "less_than_count = sum(\"<\" in text for text in all_texts)\n",
    "greater_than_count = sum(\">\" in text for text in all_texts)\n",
    "\n",
    "print(f\"Total texts with '<' character: {less_than_count}\")\n",
    "print(f\"Total texts with '>' character: {greater_than_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4aaac4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_tags(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove HTML tags from text while preserving the content between tags.\n",
    "    Special case: preserves \"<3\" (heart symbol).\n",
    "\n",
    "    Args:\n",
    "        text: The input text containing potential HTML tags\n",
    "\n",
    "    Returns:\n",
    "        Text with HTML tags removed but content preserved\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    # First, temporarily replace \"<3\" with a special marker\n",
    "    text = text.replace(\"<3\", \"HEART_SYMBOL_PLACEHOLDER\")\n",
    "\n",
    "    # Remove HTML tags\n",
    "    cleaned_text = re.sub(r\"<[^>]*>\", \"\", text)\n",
    "\n",
    "    # Restore the heart symbols\n",
    "    cleaned_text = cleaned_text.replace(\"HEART_SYMBOL_PLACEHOLDER\", \"<3\")\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Test basic HTML tag removal\n",
    "assert clean_html_tags(\"<p>Hello world</p>\") == \"Hello world\"\n",
    "\n",
    "# Test nested tags\n",
    "assert clean_html_tags(\"<div><p>Nested content</p></div>\") == \"Nested content\"\n",
    "\n",
    "# Test with attributes\n",
    "assert clean_html_tags('<a href=\"https://example.com\">Link text</a>') == \"Link text\"\n",
    "\n",
    "# Test with multiple tags and text\n",
    "assert clean_html_tags(\"<h1>Title</h1><p>Paragraph</p>\") == \"TitleParagraph\"\n",
    "\n",
    "# Test with the special case of \"<3\" (heart symbol)\n",
    "assert (\n",
    "    clean_html_tags(\n",
    "        \"I LUVED IT SO MUCH <3 <br /><br />its about a women...<br /><br /> her<br /><br />\"\n",
    "    )\n",
    "    == \"I LUVED IT SO MUCH <3 its about a women... her\"\n",
    ")\n",
    "\n",
    "# Test with mixed content\n",
    "assert (\n",
    "    clean_html_tags(\"Text with <b>bold</b> and <i>italic</i>\")\n",
    "    == \"Text with bold and italic\"\n",
    ")\n",
    "\n",
    "# Test with \"<em>\"\n",
    "assert clean_html_tags(\"<em>This is emphasized</em>\") == \"This is emphasized\"\n",
    "\n",
    "# Test with </SPOILER>\n",
    "assert clean_html_tags(\"</SPOILER>This is a spoiler</SPOILER>\") == \"This is a spoiler\"\n",
    "\n",
    "# Test with empty tags\n",
    "assert clean_html_tags(\"<br><hr>Text\") == \"Text\"\n",
    "\n",
    "# Test with no tags\n",
    "assert clean_html_tags(\"Plain text without tags\") == \"Plain text without tags\"\n",
    "\n",
    "assert any(\n",
    "    \"<3\" in text for text in all_texts\n",
    ")  # check that the heart symbol is still in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7c495be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = [clean_html_tags(text) for text in all_texts]\n",
    "\n",
    "assert any(\n",
    "    \"<3\" in text for text in all_texts\n",
    ")  # check that the heart symbol is still in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d2c3770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_MAP = {\n",
    "    \"%\": \" \",  # -> replace it with a space (will be tokenized later)\n",
    "    \"´\": \"'\",  # -> Unify apostrophes. Apostrophes are important in words like \"don't\"\n",
    "    \")\": \" \",\n",
    "    \"}\": \" \",\n",
    "    \"-\": None,  # --> will be removed or kept later, depending on the context\n",
    "    \"/\": \" \",\n",
    "    \"$\": \" \",\n",
    "    \"_\": \" \",  # in the dataset, it's used to make text in italics, so we remove it since that's only formatting\n",
    "    \"£\": \" \",\n",
    "    \"\\\\\": \" \",\n",
    "    \"'\": \"'\",\n",
    "    \"“\": \" \",\n",
    "    \"~\": \" \",\n",
    "    \"¦\": \" \",\n",
    "    \"»\": \" \",\n",
    "    \"^\": \" \",\n",
    "    \"¨\": \" \",\n",
    "    \"(\": \" \",\n",
    "    \"”\": \" \",\n",
    "    \"|\": \" \",\n",
    "    \"’\": \"'\",\n",
    "    \".\": \" \",\n",
    "    \"[\": \" \",\n",
    "    \"°\": \" \",\n",
    "    \"¡\": \" \",\n",
    "    \"·\": \" \",\n",
    "    \"!\": \" \",\n",
    "    \"+\": \" \",\n",
    "    \"¤\": \" \",\n",
    "    \"¿\": \" \",\n",
    "    \";\": \" \",\n",
    "    \"{\": \" \",\n",
    "    '\"': \" \",\n",
    "    \"?\": \" \",\n",
    "    \"<\": \" \",\n",
    "    \">\": \" \",\n",
    "    \"–\": \" \",\n",
    "    \"®\": \" \",\n",
    "    \"*\": \" \",\n",
    "    \"=\": \" \",\n",
    "    \"#\": \" \",\n",
    "    \"]\": \" \",\n",
    "    \"…\": \" \",\n",
    "    \":\": \" \",\n",
    "    \",\": \" \",\n",
    "    \"&\": \" \",\n",
    "    \"₤\": \" \",\n",
    "    \"‘\": \"'\",\n",
    "    \"§\": \" \",\n",
    "    \"`\": \" \",\n",
    "    \"@\": \" \",\n",
    "    \"«\": \" \",\n",
    "    \"½\": \" \",\n",
    "    \"¢\": \" \",\n",
    "    \"©\": \" \",\n",
    "    \"″\": \" \",\n",
    "    \"，\": \" \",\n",
    "    \"、\": \" \",\n",
    "    \"★\": \" \",\n",
    "    \"▼\": \" \",\n",
    "}\n",
    "\n",
    "\n",
    "def get_rid_of_non_alphanumeric_characters(text: str, char_map: dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Remove non-alphanumeric characters from text based on the provided character map.\n",
    "\n",
    "    Args:\n",
    "        text: The input text to clean\n",
    "        char_map: A dictionary mapping characters to their replacements. If the replacement is None, the character will be kept as is.\n",
    "\n",
    "    Returns:\n",
    "        Text with non-alphanumeric characters replaced as specified in the character map.\n",
    "    \"\"\"\n",
    "\n",
    "    for char, replacement in char_map.items():\n",
    "        if replacement is None:\n",
    "            continue  # keep the character as is\n",
    "        else:\n",
    "            text = text.replace(char, replacement)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "assert get_rid_of_non_alphanumeric_characters(\"Hello world\", CHAR_MAP) == \"Hello world\"\n",
    "assert (\n",
    "    get_rid_of_non_alphanumeric_characters(\"Hello @ world\", CHAR_MAP) == \"Hello   world\"\n",
    ")\n",
    "assert (\n",
    "    get_rid_of_non_alphanumeric_characters(\n",
    "        \"only £300 000 and 7 weeks to write.\", CHAR_MAP\n",
    "    )\n",
    "    == \"only  300 000 and 7 weeks to write \"\n",
    ")\n",
    "\n",
    "\n",
    "def keep_or_remove_dashes(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Processes dashes in a text string based on their context.\n",
    "\n",
    "    Keeps dashes that appear to be part of a word, specifically those\n",
    "    immediately surrounded by alphanumeric characters. Replaces all\n",
    "    other dashes (e.g., standalone dashes, dashes next to spaces,\n",
    "    consecutive dashes not surrounded by alphanumeric characters)\n",
    "    with a single space.\n",
    "\n",
    "    Args:\n",
    "        text: The input text string.\n",
    "\n",
    "    Returns:\n",
    "        The processed text string where dashes not part of words are\n",
    "        replaced by spaces.\n",
    "\n",
    "    Examples:\n",
    "        >>> keep_or_remove_dash(\"a-composed-word\")\n",
    "        'a-composed-word'\n",
    "        >>> keep_or_remove_dash(\"an hyphen in - the - middle - of a word\")\n",
    "        'an hyphen in   the   middle   of a word'\n",
    "        >>> keep_or_remove_dash(\" - this is a bullet list but this-is-a-composed-word\")\n",
    "        '   this is a bullet list but this-is-a-composed-word'\n",
    "        >>> keep_or_remove_dash(\"multiple---consecutive---dashes\")\n",
    "        'multiple   consecutive   dashes'\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    n = len(text)\n",
    "    for i, char in enumerate(text):\n",
    "        if char == \"-\":\n",
    "            # Check if the dash is part of a word (surrounded by alphanumeric chars)\n",
    "            is_part_of_word = (\n",
    "                i > 0 and text[i - 1].isalnum() and i < n - 1 and text[i + 1].isalnum()\n",
    "            )\n",
    "\n",
    "            if is_part_of_word:\n",
    "                result.append(\"-\")\n",
    "            else:\n",
    "                # Replace dash with space if it's not part of a word\n",
    "                result.append(\" \")\n",
    "        else:\n",
    "            result.append(char)\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "assert keep_or_remove_dashes(\"a-composed-word\") == \"a-composed-word\"\n",
    "assert (\n",
    "    keep_or_remove_dashes(\"an hyphen in - the - middle - of a word\")\n",
    "    == \"an hyphen in   the   middle   of a word\"\n",
    ")\n",
    "assert (\n",
    "    keep_or_remove_dashes(\" - this is a bullet list but this-is-a-composed-word\")\n",
    "    == \"   this is a bullet list but this-is-a-composed-word\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "664185bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = [\n",
    "    get_rid_of_non_alphanumeric_characters(text, CHAR_MAP) for text in all_texts\n",
    "]\n",
    "\n",
    "all_texts = [keep_or_remove_dashes(text) for text in all_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407fadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Remaining non-alphanumeric characters:\")\n",
    "find_non_alphanumeric(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f39b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "char = \"-\"\n",
    "for text in [text for text in all_texts if char in text][:50]:\n",
    "    # Find all positions where the character appears\n",
    "    positions = [i for i, c in enumerate(text) if c == char]\n",
    "\n",
    "    if positions:\n",
    "        # For each position, show context (5 characters before and after)\n",
    "        for pos in positions:\n",
    "            start = max(0, pos - 10)\n",
    "            end = min(len(text), pos + 10)  # +6 to include the character at pos+5\n",
    "            context = text[start:end]\n",
    "            print(f\"...{context}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e8c3df",
   "metadata": {},
   "source": [
    "### Lowercase the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b86b107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = [text.lower() for text in all_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0997c0ba",
   "metadata": {},
   "source": [
    "### Tokenize text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19938b",
   "metadata": {},
   "source": [
    "Since we already replaced all unwanted and punctuation characters with spaces, we only need to split by spaces ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23da1930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_clean_tokens(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Splits text into tokens by whitespace and cleans individual tokens\n",
    "    (e.g., removes leading/trailing apostrophes).\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        # Remove leading/trailing apostrophes that might remain\n",
    "        cleaned_token = token.strip(\"'\")\n",
    "        # Remove trailing 's that might remain\n",
    "        cleaned_token = cleaned_token.rstrip(\"'s\")\n",
    "\n",
    "        if cleaned_token:  # Avoid empty strings\n",
    "            cleaned_tokens.append(cleaned_token)\n",
    "\n",
    "    assert all(\n",
    "        not re.search(r\"\\s\", t) for t in cleaned_tokens\n",
    "    )  # check that there is no whitespace in the tokens\n",
    "\n",
    "    return cleaned_tokens\n",
    "\n",
    "\n",
    "assert tokenize_and_clean_tokens(\"'Hello'\") == [\"Hello\"]\n",
    "assert tokenize_and_clean_tokens(\"'Hello' world\") == [\"Hello\", \"world\"]\n",
    "assert tokenize_and_clean_tokens(\"'Hello' world\") == [\"Hello\", \"world\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = [t for text in all_texts for t in tokenize_and_clean_tokens(text)]\n",
    "all_unique_tokens = set(all_tokens)\n",
    "\n",
    "print(f\"{len(all_tokens)=}\")\n",
    "print(f\"Unique tokens : {len(all_unique_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d32246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(all_unique_tokens))[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa5d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in list(all_unique_tokens) if \"'\" in t or \"’\" in t or '\"' in t][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b42d2bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_unique_tokens.txt\", \"w\") as f:\n",
    "    for token in sorted(all_unique_tokens):\n",
    "        f.write(f\"{token}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29f21ce",
   "metadata": {},
   "source": [
    "### Tokens frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d2b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tokens_counter: Counter[str] = Counter(all_tokens)\n",
    "\n",
    "# Get the 15 most common tokens\n",
    "most_common_tokens = tokens_counter.most_common(15)\n",
    "print(\"15 most common tokens (corpus frequency):\")\n",
    "for token, _ in most_common_tokens:\n",
    "    print(token)\n",
    "\n",
    "# Get the 15 least common tokens\n",
    "least_common_tokens = tokens_counter.most_common()[:-16:-1]\n",
    "print(\"\\n15 least common tokens (corpus frequency):\")\n",
    "for token, _ in least_common_tokens:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count document frequency using Counter\n",
    "tokens_counter: Counter[str] = Counter()\n",
    "\n",
    "for text in all_texts:\n",
    "    doc_tokens = set(tokenize_and_clean_tokens(text))\n",
    "    tokens_counter.update(doc_tokens)\n",
    "\n",
    "# Show the 15 most frequent tokens by document frequency\n",
    "most_common_df_tokens = tokens_counter.most_common(15)\n",
    "print(\"15 most common tokens (document frequency):\")\n",
    "for token, freq in most_common_df_tokens:\n",
    "    print(f\"{token}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "def plot_wordcloud(tokens_counts: Counter[str]) -> None:\n",
    "    wc = WordCloud(width=800, height=400, background_color=\"white\")\n",
    "    wc.generate_from_frequencies(tokens_counts)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Token Frequency Word Cloud\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_wordcloud(tokens_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8533e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different threshold percentages for removing most frequent tokens\n",
    "threshold_percentages = [\n",
    "    0.01,\n",
    "    0.02,\n",
    "    0.05,\n",
    "    0.1,\n",
    "    0.2,\n",
    "    0.5,\n",
    "    1,\n",
    "    5,\n",
    "    10,\n",
    "]  # Remove top X% most frequent tokens\n",
    "\n",
    "# Create a figure with subplots for each threshold\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, THRESHOLD_PERCENTAGE in enumerate(threshold_percentages, 1):\n",
    "    # Calculate how many tokens to remove\n",
    "    total_unique_tokens = len(tokens_counter)\n",
    "    n_tokens_to_remove = int(total_unique_tokens * THRESHOLD_PERCENTAGE / 100)\n",
    "\n",
    "    print(f\"\\n--- Threshold: {THRESHOLD_PERCENTAGE}% ---\")\n",
    "    print(f\"Total unique tokens: {total_unique_tokens}\")\n",
    "    print(\n",
    "        f\"Removing top {THRESHOLD_PERCENTAGE}% ({n_tokens_to_remove}) most frequent tokens\"\n",
    "    )\n",
    "\n",
    "    # Get the tokens to remove (the most frequent ones)\n",
    "    tokens_to_remove = [\n",
    "        token for token, _ in tokens_counter.most_common(n_tokens_to_remove)\n",
    "    ]\n",
    "\n",
    "    # Create a new counter without the removed tokens\n",
    "    filtered_tokens_counter = Counter(\n",
    "        {\n",
    "            token: count\n",
    "            for token, count in tokens_counter.items()\n",
    "            if token not in tokens_to_remove\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Tokens remaining after filtering: {len(filtered_tokens_counter)}\")\n",
    "\n",
    "    # Compare the original and filtered token counts\n",
    "    print(f\"Original total token count: {sum(tokens_counter.values())}\")\n",
    "    print(f\"Filtered total token count: {sum(filtered_tokens_counter.values())}\")\n",
    "    print(\n",
    "        f\"Percentage of tokens removed: {(sum(tokens_counter.values()) - sum(filtered_tokens_counter.values())) / sum(tokens_counter.values()) * 100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # Display some of the removed tokens\n",
    "    print(\"Sample of removed tokens (top 5):\")\n",
    "    for token in tokens_to_remove[:5]:\n",
    "        print(f\"'{token}' (count: {tokens_counter[token]})\")\n",
    "\n",
    "    # Create a subplot for this threshold\n",
    "    # Dynamically determine subplot grid size based on number of thresholds\n",
    "    import math\n",
    "\n",
    "    n_thresholds = len(threshold_percentages)\n",
    "    n_cols = math.ceil(math.sqrt(n_thresholds))\n",
    "    n_rows = math.ceil(n_thresholds / n_cols)\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "\n",
    "    # Generate and display wordcloud\n",
    "    wc = WordCloud(width=800, height=400, background_color=\"white\")\n",
    "    wc.generate_from_frequencies(filtered_tokens_counter)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud - {THRESHOLD_PERCENTAGE}% threshold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the most frequent tokens after filtering with 5% threshold (as an example)\n",
    "THRESHOLD_PERCENTAGE = 1\n",
    "n_tokens_to_remove = int(total_unique_tokens * THRESHOLD_PERCENTAGE / 100)\n",
    "tokens_to_remove = {\n",
    "    token for token, _ in tokens_counter.most_common(n_tokens_to_remove)\n",
    "}\n",
    "filtered_tokens_counter = Counter(\n",
    "    {\n",
    "        token: count\n",
    "        for token, count in tokens_counter.items()\n",
    "        if token not in tokens_to_remove\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nMost frequent tokens after filtering with {THRESHOLD_PERCENTAGE}% threshold (top 10):\"\n",
    ")\n",
    "for token, count in filtered_tokens_counter.most_common(10):\n",
    "    print(f\"'{token}' (count: {count})\")\n",
    "\n",
    "filtered_unique_tokens = {\n",
    "    token for token in tokens_counter if token not in tokens_to_remove\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80917b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filtered_tokens.txt\", \"w\") as f:\n",
    "    for token in sorted(filtered_unique_tokens):\n",
    "        f.write(f\"{token}\\n\")\n",
    "\n",
    "list(sorted(filtered_unique_tokens))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab6b5a",
   "metadata": {},
   "source": [
    "\n",
    "### Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214bf2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "def stem_words(words: Iterable[str], stemmer: PorterStemmer | None = None) -> list[str]:\n",
    "    if not stemmer:\n",
    "        stemmer = PorterStemmer()\n",
    "\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "\n",
    "stem_words([\"running\", \"runs\", \"ran\", \"easily\", \"fairly\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b093d",
   "metadata": {},
   "source": [
    "### Tokenize tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tokens before stemming :\n",
    "print(\n",
    "    f\"Number of unique tokens before stemming, after removing {THRESHOLD_PERCENTAGE}% most common : {len(filtered_unique_tokens)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_unique_tokens: set[str] = set(stem_words(filtered_unique_tokens))\n",
    "\n",
    "print(f\"Number of unique tokens after stemming : {len(stemmed_unique_tokens)}\")\n",
    "\n",
    "\n",
    "for token in list(stemmed_unique_tokens)[:10]:\n",
    "    print(f\"{token}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fb8962f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokens.txt\", \"w\") as f:\n",
    "    for token in sorted(stemmed_unique_tokens):\n",
    "        f.write(f\"{token}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9044aac-ffe8-4c00-8c1f-72e74ad1f214",
   "metadata": {},
   "source": [
    "## Build the bag of words (BOW)\n",
    "For building the matrix for the representation of bag of words use the previously built vocabulary and tokens for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b877c-30f7-4fa3-9ed0-29229aa421b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bow_vocabulary_list = sorted(list(stemmed_unique_tokens))\n",
    "final_bow_vocabulary_map = {\n",
    "    token: i for i, token in enumerate(final_bow_vocabulary_list)\n",
    "}\n",
    "print(f\"Final BoW vocabulary size: {len(final_bow_vocabulary_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c3809-f76c-4246-b4d3-07b88c2780a1",
   "metadata": {},
   "source": [
    "# Task 3: Comparing BOWs\n",
    "\n",
    "1. Use the previous steps to build a bag of words with the training data in which the tokens that appear more than 1% are discarded. \n",
    "1. Compare your BOW with LIBSVM BOW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17defc98-b2e2-4b18-b31e-53f5e591ed54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25602e22-bd28-468b-bfc7-331e9e60fcc8",
   "metadata": {},
   "source": [
    "# Task 4: Train a Random Forest and test it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "80371ade-b3ba-4400-a53a-d992986c2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431e66c7-5999-4861-a3ea-c172552d1f01",
   "metadata": {},
   "source": [
    "# Task 5: Markov chain\n",
    "Tip: For memory optimization use sparse structures not a matrix mostrly filled with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d2a401-c7e0-4728-a7e0-cc4901ac9b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aa44a3b-38b1-4618-81f0-080e613b7f0f",
   "metadata": {},
   "source": [
    "## Pre-process data\n",
    "Read the data and using the previous built functions for the BOW representation create a list of words per each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a587818-9507-4e35-9698-82db66404a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b344c6d-a9c3-4422-a464-25f58c875ba4",
   "metadata": {},
   "source": [
    "## Chain words\n",
    "Identify all the possible pairs of words (w0, w1) in all the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff4f1f-5c76-44d5-9711-57e12b5c2f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3ce3183-6431-4a4c-a3a8-ed9fa51f7680",
   "metadata": {},
   "source": [
    "## Initialize the Markov's Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edee359-021e-4e0a-99d6-72b3d86ecdd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3479a238-1e1e-4884-a951-cda7f848d40d",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "Here you could also try to generate words for the unlabeled part of the dataset. Try to meassure the quality of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d8f92-a060-4f0b-8576-2e43bea89189",
   "metadata": {},
   "source": [
    "## Theoretical Questions\n",
    "\n",
    "### 1. Categorization of Tasks\n",
    "\n",
    "Define whether Tasks 2, 4, and 5 fall under NLG, NLU, or NLP.\n",
    "\n",
    "### 2. Text Processing Pipeline Discussion\n",
    "\n",
    "Discuss the advantages and drawbacks of steps like stemming and punctuation removal.\n",
    "\n",
    "### 3. Review Linguistic Concepts\n",
    "\n",
    "Define:\n",
    "\n",
    "- Polysemy\n",
    "- Zeugma\n",
    "- Homonyms\n",
    "- Homographs\n",
    "- Homophones\n",
    "\n",
    "Then answer:\n",
    "\n",
    "- Are these concepts important in NLP? Why?\n",
    "- How do they impact a BoW representation?\n",
    "\n",
    "### 4. Markov Model Performance\n",
    "\n",
    "Think about the performance of the Markov model, is it good? Why or why not?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
